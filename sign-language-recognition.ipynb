{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e244664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae464d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/alphabet/sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d64b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8af356",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_df.drop('label', axis=1), train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7f1815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27455, 784), (27455,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2c0ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([dtype('int64')], dtype=object), dtype('int64'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X.dtypes), y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aefdee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac7aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0614382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a1dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd8e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([27455, 28, 28, 1]), (27455, 24))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fca390",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X[:25000], X[25000:]\n",
    "y_train, y_valid = y[:25000], y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1746470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924a59d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368bf529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x20eaa7a2ca0>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0], cmap='gray'), y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689a381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(24, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78cfb24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,704\n",
      "Trainable params: 407,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a880adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6381e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_cb = keras.callbacks.ModelCheckpoint('initial-end-to-end', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba45325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.7716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 25s 21ms/step - loss: 0.7405 - accuracy: 0.7716 - val_loss: 0.0184 - val_accuracy: 0.9988\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 6.6632e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 4.3761e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 4.3748e-04 - accuracy: 1.0000 - val_loss: 2.7369e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 2.0137e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 20ms/step - loss: 2.0132e-04 - accuracy: 1.0000 - val_loss: 1.4363e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "780/782 [============================>.] - ETA: 0s - loss: 9.4086e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 9.4030e-05 - accuracy: 1.0000 - val_loss: 7.0379e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "780/782 [============================>.] - ETA: 0s - loss: 5.0396e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 5.0389e-05 - accuracy: 1.0000 - val_loss: 4.1547e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.9544e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 2.9544e-05 - accuracy: 1.0000 - val_loss: 2.3519e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "779/782 [============================>.] - ETA: 0s - loss: 1.8174e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 21ms/step - loss: 1.8149e-05 - accuracy: 1.0000 - val_loss: 1.5866e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "780/782 [============================>.] - ETA: 0s - loss: 1.0699e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 1.0692e-05 - accuracy: 1.0000 - val_loss: 8.8468e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "778/782 [============================>.] - ETA: 0s - loss: 6.2712e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 6.2655e-06 - accuracy: 1.0000 - val_loss: 5.9392e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 3.3291e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 3.3284e-06 - accuracy: 1.0000 - val_loss: 3.0666e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 2.1350e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 2.1343e-06 - accuracy: 1.0000 - val_loss: 2.1152e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.3007e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 1.3007e-06 - accuracy: 1.0000 - val_loss: 1.5877e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "778/782 [============================>.] - ETA: 0s - loss: 7.9804e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 7.9762e-07 - accuracy: 1.0000 - val_loss: 1.1102e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 5.0215e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 5.0233e-07 - accuracy: 1.0000 - val_loss: 4.9291e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "780/782 [============================>.] - ETA: 0s - loss: 3.3197e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 3.3198e-07 - accuracy: 1.0000 - val_loss: 4.1293e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 2.0277e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 2.0276e-07 - accuracy: 1.0000 - val_loss: 2.3808e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "777/782 [============================>.] - ETA: 0s - loss: 1.3761e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: initial-end-to-end\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 1.3735e-07 - accuracy: 1.0000 - val_loss: 1.6723e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 9.8567e-08 - accuracy: 1.0000 - val_loss: 4.6305e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0899 - accuracy: 0.9793 - val_loss: 3.2959e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[save_best_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bcca6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7405094504356384,\n",
       "  0.011254285462200642,\n",
       "  0.00043748237658292055,\n",
       "  0.00020131551718804985,\n",
       "  9.403005242347717e-05,\n",
       "  5.038879316998646e-05,\n",
       "  2.954396404675208e-05,\n",
       "  1.814886854845099e-05,\n",
       "  1.0692021533031948e-05,\n",
       "  6.265496722335229e-06,\n",
       "  3.3283540687989444e-06,\n",
       "  2.1343234948290046e-06,\n",
       "  1.300704980167211e-06,\n",
       "  7.97622817572119e-07,\n",
       "  5.023313178753597e-07,\n",
       "  3.3198188020833186e-07,\n",
       "  2.0276041823308333e-07,\n",
       "  1.3734799608755566e-07,\n",
       "  9.856679383801747e-08,\n",
       "  0.08989246934652328],\n",
       " 'accuracy': [0.77156001329422,\n",
       "  0.9977200031280518,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9792799949645996],\n",
       " 'val_loss': [0.01839500479400158,\n",
       "  0.0006663150852546096,\n",
       "  0.0002736948081292212,\n",
       "  0.0001436274469597265,\n",
       "  7.037875184323639e-05,\n",
       "  4.154695488978177e-05,\n",
       "  2.351945840928238e-05,\n",
       "  1.586629332450684e-05,\n",
       "  8.846803211781662e-06,\n",
       "  5.9392446019046474e-06,\n",
       "  3.0666080874652835e-06,\n",
       "  2.1152236513444223e-06,\n",
       "  1.5876569250394823e-06,\n",
       "  1.1102185908384854e-06,\n",
       "  4.92906963245332e-07,\n",
       "  4.1293222352578596e-07,\n",
       "  2.3807763227523537e-07,\n",
       "  1.6723249984806898e-07,\n",
       "  4.630461262422614e-06,\n",
       "  0.00032958859810605645],\n",
       " 'val_accuracy': [0.9987779855728149,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59c70522",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('initial-end-to-end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "451bfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/alphabet/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0d1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df.drop('label', axis=1), test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e461092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf.reshape(X_test, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfa71db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = label_binarizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9305d7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 6ms/step - loss: 116.5061 - accuracy: 0.9034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[116.50614166259766, 0.9033742547035217]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab6fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
